import requests
from telegram import Update
from telegram.ext import Application, CommandHandler, MessageHandler, filters, ContextTypes

# –¢–æ–∫–µ–Ω Telegram –æ—Ç BotFather
TELEGRAM_TOKEN = "–°–Æ–î–ê_–í–°–¢–ê–í–¨_–¢–í–û–ô_TELEGRAM_TOKEN"
# –¢–æ–∫–µ–Ω Hugging Face (—Ç–≤–æ–π –∫–ª—é—á)
HF_TOKEN = "import os
HF_TOKEN = os.environ["HF_TOKEN"]
"

# Endpoint Hugging Face –¥–ª—è Llama-3 (–º–æ–∂–Ω–æ –º–µ–Ω—è—Ç—å –Ω–∞ –¥—Ä—É–≥–∏–µ —Ç–æ–ø–æ–≤—ã–µ –º–æ–¥–µ–ª–∏)
HF_API_URL = "https://api-inference.huggingface.co/models/meta-llama/Meta-Llama-3-8B-Instruct"

def get_hf_answer(user_message):
    headers = {"Authorization": f"Bearer {HF_TOKEN}"}
    payload = {"inputs": user_message}
    response = requests.post(HF_API_URL, headers=headers, json=payload)
    result = response.json()
    # –ú–æ–¥–µ–ª–∏ –≤–æ–∑–≤—Ä–∞—â–∞—é—Ç –æ—Ç–≤–µ—Ç –≤ —Ä–∞–∑–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ ‚Äî –∏—â–µ–º 'generated_text'
    if isinstance(result, list) and len(result) > 0 and 'generated_text' in result[0]:
        return result[0]['generated_text']
    return "–ò–∑–≤–∏–Ω–∏, —è –Ω–µ —Å–º–æ–≥ –ø–æ–ª—É—á–∏—Ç—å –æ—Ç–≤–µ—Ç –æ—Ç –º–æ–¥–µ–ª–∏."

async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text("–ü—Ä–∏–≤–µ—Ç! –Ø –î–∏–∞–Ω–∞ –Ω–∞ Hugging Face Llama-3 üôÇ –ó–∞–¥–∞–≤–∞–π –≤–æ–ø—Ä–æ—Å—ã!")

async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_message = update.message.text
    try:
        answer = get_hf_answer(user_message)
        await update.message.reply_text(answer)
    except Exception as e:
        await update.message.reply_text("–ò–∑–≤–∏–Ω–∏, –≤–æ–∑–Ω–∏–∫–ª–∞ –æ—à–∏–±–∫–∞ üòî")
        print(e)

def main():
    application = Application.builder().token(TELEGRAM_TOKEN).build()
    application.add_handler(CommandHandler("start", start))
    application.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message))
    application.run_polling()

if __name__ == "__main__":
    main()
